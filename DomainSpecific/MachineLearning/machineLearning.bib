

@article{Chen96,
	author = {Chen, Lichao and Singh, Sudhir and Kailath, Thomas and Roychowdhury, Vwani},
	title = {Brain-inspired automated visual object discovery and detection},
	volume = {116},
	number = {1},
	pages = {96--105},
	year = {2019},
	doi = {10.1073/pnas.1802103115},
	publisher = {National Academy of Sciences},
	abstract = {The Internet contains millions of videos and images of objects, captured contextually, just as they would appear in their natural environments. Such access to large-scale data has injected an urgency to an age-old query: Can one automatically browse these data, as a human would, to construct brain-like and computationally tractable models of the visual world? If successful, many of the scalability and robustness limitations of existing computer vision methodologies, which primarily rely on supervised frameworks requiring manually labeled exemplars, will be removed. As a step toward solving this problem, we leverage widely accepted findings in the fields of cognitive psychology and neurophysiology to develop an unsupervised framework for automated isolation of objects and their efficient detection and localization in new environments.Despite significant recent progress, machine vision systems lag considerably behind their biological counterparts in performance, scalability, and robustness. A distinctive hallmark of the brain is its ability to automatically discover and model objects, at multiscale resolutions, from repeated exposures to unlabeled contextual data and then to be able to robustly detect the learned objects under various nonideal circumstances, such as partial occlusion and different view angles. Replication of such capabilities in a machine would require three key ingredients: (i) access to large-scale perceptual data of the kind that humans experience, (ii) flexible representations of objects, and (iii) an efficient unsupervised learning algorithm. The Internet fortunately provides unprecedented access to vast amounts of visual data. This paper leverages the availability of such data to develop a scalable framework for unsupervised learning of object prototypes{\textemdash}brain-inspired flexible, scale, and shift invariant representations of deformable objects (e.g., humans, motorcycles, cars, airplanes) comprised of parts, their different configurations and views, and their spatial relationships. Computationally, the object prototypes are represented as geometric associative networks using probabilistic constructs such as Markov random fields. We apply our framework to various datasets and show that our approach is computationally scalable and can construct accurate and operational part-aware object models much more efficiently than in much of the recent computer vision literature. We also present efficient algorithms for detection and localization in new scenes of objects and their partial views.},
	issn = {0027-8424},
	URL = {https://www.pnas.org/content/116/1/96},
	eprint = {https://www.pnas.org/content/116/1/96.full.pdf},
	journal = {Proceedings of the National Academy of Sciences},
	file={Docs/chen2018.pdf}
}



@ARTICLE{2018arXiv180203426M,
       author = {{McInnes}, Leland and {Healy}, John and {Melville}, James},
        title = "{UMAP: Uniform Manifold Approximation and Projection for Dimension
        Reduction}",
      journal = {arXiv e-prints},
     keywords = {Statistics - Machine Learning, Computer Science - Computational
        Geometry, Computer Science - Machine Learning},
         year = 2018,
        month = Feb,
          eid = {arXiv:1802.03426},
        pages = {arXiv:1802.03426},
archivePrefix = {arXiv},
       eprint = {1802.03426},
 primaryClass = {stat.ML},
       adsurl = {https://ui.adsabs.harvard.edu/#abs/2018arXiv180203426M},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	file={Docs/1802.03426.pdf}
}





@article{MasseE10467,
	author = {Masse, Nicolas Y. and Grant, Gregory D. and Freedman, David J.},
	title = {Alleviating catastrophic forgetting using context-dependent gating and synaptic stabilization},
	volume = {115},
	number = {44},
	pages = {E10467--E10475},
	year = {2018},
	doi = {10.1073/pnas.1803839115},
	publisher = {National Academy of Sciences},
	abstract = {Artificial neural networks can suffer from catastrophic forgetting, in which learning a new task causes the network to forget how to perform previous tasks. While previous studies have proposed various methods that can alleviate forgetting over small numbers (⩽10) of tasks, it is uncertain whether they can prevent forgetting across larger numbers of tasks. In this study, we propose a neuroscience-inspired scheme, called {\textquotedblleft}context-dependent gating,{\textquotedblright} in which mostly nonoverlapping sets of units are active for any one task. Importantly, context-dependent gating has a straightforward implementation, requires little extra computational overhead, and when combined with previous methods to stabilize connection weights, can allow networks to maintain high performance across large numbers of sequentially presented tasks.Humans and most animals can learn new tasks without forgetting old ones. However, training artificial neural networks (ANNs) on new tasks typically causes them to forget previously learned tasks. This phenomenon is the result of {\textquotedblleft}catastrophic forgetting,{\textquotedblright} in which training an ANN disrupts connection weights that were important for solving previous tasks, degrading task performance. Several recent studies have proposed methods to stabilize connection weights of ANNs that are deemed most important for solving a task, which helps alleviate catastrophic forgetting. Here, drawing inspiration from algorithms that are believed to be implemented in vivo, we propose a complementary method: adding a context-dependent gating signal, such that only sparse, mostly nonoverlapping patterns of units are active for any one task. This method is easy to implement, requires little computational overhead, and allows ANNs to maintain high performance across large numbers of sequentially presented tasks, particularly when combined with weight stabilization. We show that this method works for both feedforward and recurrent network architectures, trained using either supervised or reinforcement-based learning. This suggests that using multiple, complementary methods, akin to what is believed to occur in the brain, can be a highly effective strategy to support continual learning.},
	issn = {0027-8424},
	URL = {http://www.pnas.org/content/115/44/E10467},
	eprint = {http://www.pnas.org/content/115/44/E10467.full.pdf},
	journal = {Proceedings of the National Academy of Sciences},
	file={Docs/10.1073@pnas.1803839115.pdf}
}



@article{specht1990probabilistic,
  title={Probabilistic neural networks},
  author={Specht, Donald F},
  journal={Neural networks},
  volume={3},
  number={1},
  pages={109--118},
  year={1990},
  publisher={Elsevier},
  file={Docs/specht1990.pdf}
}



@Article{Ortin2015,
  author        = {Ortín, S. and Soriano, M. C. and Pesquera, L. and Brunner, D. and San-Martín, D. and Fischer, I. and Mirasso, C. R. and Gutiérrez, J. M.},
  title         = {A Unified Framework for Reservoir Computing and Extreme Learning Machines based on a Single Time-delayed Neuron},
  journal       = {Scientific Reports},
  year          = {2015},
  volume        = {5},
  pages         = {14945},
  month         = oct,
  publisher     = {The Author(s)},
  url           = {http://dx.doi.org/10.1038/srep14945},
  file={Docs/srep14945.pdf}
}




@inproceedings{fredrikson2015model,
  title={Model inversion attacks that exploit confidence information and basic countermeasures},
  author={Fredrikson, Matt and Jha, Somesh and Ristenpart, Thomas},
  booktitle={Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security},
  pages={1322--1333},
  year={2015},
  organization={ACM},
  file={Docs/fjr2015ccs.pdf}
}




@ARTICLE{2018arXiv180704644V,
   author = {{Veale}, M. and {Binns}, R. and {Edwards}, L.},
    title = "{Algorithms that Remember: Model Inversion Attacks and Data Protection Law}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1807.04644},
 keywords = {Computer Science - Machine Learning, Computer Science - Cryptography and Security, Computer Science - Computers and Society},
     year = 2018,
    month = jul,
   adsurl = {http://adsabs.harvard.edu/abs/2018arXiv180704644V},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System},
    file = {Docs/1807.04644.pdf}
}





@article{marquez2018dynamical,
  title={Dynamical complexity and computation in recurrent neural networks beyond their fixed point},
  author={Marquez, Bicky A and Larger, Laurent and Jacquot, Maxime and Chembo, Yanne K and Brunner, Daniel},
  journal={Scientific reports},
  volume={8},
  number={1},
  pages={3319},
  year={2018},
  publisher={Nature Publishing Group},
  file={Docs/s41598-018-21624-2.pdf}
}


@article{gebru2017using,
  title={Using deep learning and Google Street View to estimate the demographic makeup of neighborhoods across the United States},
  author={Gebru, Timnit and Krause, Jonathan and Wang, Yilun and Chen, Duyun and Deng, Jia and Aiden, Erez Lieberman and Fei-Fei, Li},
  journal={Proceedings of the National Academy of Sciences},
  pages={201700035},
  year={2017},
  publisher={National Acad Sciences},
  file={Docs/PNAS-2017-Gebru-1700035114.pdf}
}


@article{mikkelsen2018personalizing,
  title={Personalizing deep learning models for automatic sleep staging},
  author={Mikkelsen, Kaare and de Vos, Maarten},
  journal={arXiv preprint arXiv:1801.02645},
  year={2018},
  file={Docs/1801.02645.pdf}
}


@article{raposo2017towards,
  title={Towards Deep Modeling of Music Semantics using EEG Regularizers},
  author={Raposo, Francisco and de Matos, David Martins and Ribeiro, Ricardo and Tang, Suhua and Yu, Yi},
  journal={arXiv preprint arXiv:1712.05197},
  year={2017},
  file={Docs/1712.05197.pdf}
}


@ARTICLE{2018arXiv180600179P,
   author = {{Philipp}, G. and {Carbonell}, J.~G.},
    title = "{The Nonlinearity Coefficient - Predicting Overfitting in Deep Neural Networks}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1806.00179},
 primaryClass = "cs.LG",
 keywords = {Computer Science - Learning, Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
     year = 2018,
    month = may,
   adsurl = {http://adsabs.harvard.edu/abs/2018arXiv180600179P},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System},
  file={Docs/1806.00179.pdf}
}



@article{hausknecht2015deep,
	Author = {Hausknecht, Matthew and Stone, Peter},
	Date-Added = {2016-03-14 18:55:31 +0000},
	Date-Modified = {2016-03-14 18:55:31 +0000},
	Journal = {arXiv preprint arXiv:1511.04143},
	Title = {Deep Reinforcement Learning in Parameterized Action Space},
	Year = {2015},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFURvY3MvMTUxMS4wNDE0M3YxLnBkZtIXCxgZV05TLmRhdGFPEQIMAAAAAAIMAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADKQQYMSCsAAAQoOF0QMTUxMS4wNDE0M3YxLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA6gDHtJvzCQAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABERvY3MAEAAIAADKQOnsAAAAEQAIAADSb74UAAAAAQAgBCg4XQQoOFwDsb35AKmYegCQwikABQIVAAUCFAAAvuwAAgB1TWFjaW50b3NoIEhEOlVzZXJzOgBKdXN0ZToARG9jdW1lbnRzOgBDb21wbGV4U3lzdGVtczoAQmlibGlvOgBEb21haW5TcGVjaWZpYzoATWFjaGluZUxlYXJuaW5nOgBEb2NzOgAxNTExLjA0MTQzdjEucGRmAAAOACIAEAAxADUAMQAxAC4AMAA0ADEANAAzAHYAMQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAYFVzZXJzL0p1c3RlL0RvY3VtZW50cy9Db21wbGV4U3lzdGVtcy9CaWJsaW8vRG9tYWluU3BlY2lmaWMvTWFjaGluZUxlYXJuaW5nL0RvY3MvMTUxMS4wNDE0M3YxLnBkZgATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKYAqwCzAsMCxQLKAtUC3gLsAvAC9wMAAwUDEgMVAycDKgMvAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAzE=}}

@inproceedings{vinyals2015show,
	Author = {Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru},
	Booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	Date-Added = {2016-03-14 18:21:08 +0000},
	Date-Modified = {2016-03-14 18:21:08 +0000},
	Pages = {3156--3164},
	Title = {Show and tell: A neural image caption generator},
	Year = {2015},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFERvY3MvMTQxMS40NTU1djEucGRm0hcLGBlXTlMuZGF0YU8RAggAAAAAAggAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAMpBBgxIKwAABCg4XQ8xNDExLjQ1NTV2MS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACEQ020M9vawAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAERG9jcwAQAAgAAMpA6ewAAAARAAgAANDPYVsAAAABACAEKDhdBCg4XAOxvfkAqZh6AJDCKQAFAhUABQIUAAC+7AACAHRNYWNpbnRvc2ggSEQ6VXNlcnM6AEp1c3RlOgBEb2N1bWVudHM6AENvbXBsZXhTeXN0ZW1zOgBCaWJsaW86AERvbWFpblNwZWNpZmljOgBNYWNoaW5lTGVhcm5pbmc6AERvY3M6ADE0MTEuNDU1NXYxLnBkZgAOACAADwAxADQAMQAxAC4ANAA1ADUANQB2ADEALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAF9Vc2Vycy9KdXN0ZS9Eb2N1bWVudHMvQ29tcGxleFN5c3RlbXMvQmlibGlvL0RvbWFpblNwZWNpZmljL01hY2hpbmVMZWFybmluZy9Eb2NzLzE0MTEuNDU1NXYxLnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgClAKoAsgK+AsACxQLQAtkC5wLrAvIC+wMAAw0DEAMiAyUDKgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMs}}
