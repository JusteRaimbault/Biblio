


@article{MasseE10467,
	author = {Masse, Nicolas Y. and Grant, Gregory D. and Freedman, David J.},
	title = {Alleviating catastrophic forgetting using context-dependent gating and synaptic stabilization},
	volume = {115},
	number = {44},
	pages = {E10467--E10475},
	year = {2018},
	doi = {10.1073/pnas.1803839115},
	publisher = {National Academy of Sciences},
	abstract = {Artificial neural networks can suffer from catastrophic forgetting, in which learning a new task causes the network to forget how to perform previous tasks. While previous studies have proposed various methods that can alleviate forgetting over small numbers (⩽10) of tasks, it is uncertain whether they can prevent forgetting across larger numbers of tasks. In this study, we propose a neuroscience-inspired scheme, called {\textquotedblleft}context-dependent gating,{\textquotedblright} in which mostly nonoverlapping sets of units are active for any one task. Importantly, context-dependent gating has a straightforward implementation, requires little extra computational overhead, and when combined with previous methods to stabilize connection weights, can allow networks to maintain high performance across large numbers of sequentially presented tasks.Humans and most animals can learn new tasks without forgetting old ones. However, training artificial neural networks (ANNs) on new tasks typically causes them to forget previously learned tasks. This phenomenon is the result of {\textquotedblleft}catastrophic forgetting,{\textquotedblright} in which training an ANN disrupts connection weights that were important for solving previous tasks, degrading task performance. Several recent studies have proposed methods to stabilize connection weights of ANNs that are deemed most important for solving a task, which helps alleviate catastrophic forgetting. Here, drawing inspiration from algorithms that are believed to be implemented in vivo, we propose a complementary method: adding a context-dependent gating signal, such that only sparse, mostly nonoverlapping patterns of units are active for any one task. This method is easy to implement, requires little computational overhead, and allows ANNs to maintain high performance across large numbers of sequentially presented tasks, particularly when combined with weight stabilization. We show that this method works for both feedforward and recurrent network architectures, trained using either supervised or reinforcement-based learning. This suggests that using multiple, complementary methods, akin to what is believed to occur in the brain, can be a highly effective strategy to support continual learning.},
	issn = {0027-8424},
	URL = {http://www.pnas.org/content/115/44/E10467},
	eprint = {http://www.pnas.org/content/115/44/E10467.full.pdf},
	journal = {Proceedings of the National Academy of Sciences},
	file={Docs/10.1073@pnas.1803839115.pdf}
}



@article{specht1990probabilistic,
  title={Probabilistic neural networks},
  author={Specht, Donald F},
  journal={Neural networks},
  volume={3},
  number={1},
  pages={109--118},
  year={1990},
  publisher={Elsevier},
  file={Docs/specht1990.pdf}
}



@Article{Ortin2015,
  author        = {Ortín, S. and Soriano, M. C. and Pesquera, L. and Brunner, D. and San-Martín, D. and Fischer, I. and Mirasso, C. R. and Gutiérrez, J. M.},
  title         = {A Unified Framework for Reservoir Computing and Extreme Learning Machines based on a Single Time-delayed Neuron},
  journal       = {Scientific Reports},
  year          = {2015},
  volume        = {5},
  pages         = {14945},
  month         = oct,
  publisher     = {The Author(s)},
  url           = {http://dx.doi.org/10.1038/srep14945},
  file={Docs/srep14945.pdf}
}




@inproceedings{fredrikson2015model,
  title={Model inversion attacks that exploit confidence information and basic countermeasures},
  author={Fredrikson, Matt and Jha, Somesh and Ristenpart, Thomas},
  booktitle={Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security},
  pages={1322--1333},
  year={2015},
  organization={ACM},
  file={Docs/fjr2015ccs.pdf}
}




@ARTICLE{2018arXiv180704644V,
   author = {{Veale}, M. and {Binns}, R. and {Edwards}, L.},
    title = "{Algorithms that Remember: Model Inversion Attacks and Data Protection Law}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1807.04644},
 keywords = {Computer Science - Machine Learning, Computer Science - Cryptography and Security, Computer Science - Computers and Society},
     year = 2018,
    month = jul,
   adsurl = {http://adsabs.harvard.edu/abs/2018arXiv180704644V},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System},
    file = {Docs/1807.04644.pdf}
}





@article{marquez2018dynamical,
  title={Dynamical complexity and computation in recurrent neural networks beyond their fixed point},
  author={Marquez, Bicky A and Larger, Laurent and Jacquot, Maxime and Chembo, Yanne K and Brunner, Daniel},
  journal={Scientific reports},
  volume={8},
  number={1},
  pages={3319},
  year={2018},
  publisher={Nature Publishing Group},
  file={Docs/s41598-018-21624-2.pdf}
}


@article{gebru2017using,
  title={Using deep learning and Google Street View to estimate the demographic makeup of neighborhoods across the United States},
  author={Gebru, Timnit and Krause, Jonathan and Wang, Yilun and Chen, Duyun and Deng, Jia and Aiden, Erez Lieberman and Fei-Fei, Li},
  journal={Proceedings of the National Academy of Sciences},
  pages={201700035},
  year={2017},
  publisher={National Acad Sciences},
  file={Docs/PNAS-2017-Gebru-1700035114.pdf}
}


@article{mikkelsen2018personalizing,
  title={Personalizing deep learning models for automatic sleep staging},
  author={Mikkelsen, Kaare and de Vos, Maarten},
  journal={arXiv preprint arXiv:1801.02645},
  year={2018},
  file={Docs/1801.02645.pdf}
}


@article{raposo2017towards,
  title={Towards Deep Modeling of Music Semantics using EEG Regularizers},
  author={Raposo, Francisco and de Matos, David Martins and Ribeiro, Ricardo and Tang, Suhua and Yu, Yi},
  journal={arXiv preprint arXiv:1712.05197},
  year={2017},
  file={Docs/1712.05197.pdf}
}


@ARTICLE{2018arXiv180600179P,
   author = {{Philipp}, G. and {Carbonell}, J.~G.},
    title = "{The Nonlinearity Coefficient - Predicting Overfitting in Deep Neural Networks}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1806.00179},
 primaryClass = "cs.LG",
 keywords = {Computer Science - Learning, Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
     year = 2018,
    month = may,
   adsurl = {http://adsabs.harvard.edu/abs/2018arXiv180600179P},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System},
  file={Docs/1806.00179.pdf}
}



@article{hausknecht2015deep,
	Author = {Hausknecht, Matthew and Stone, Peter},
	Date-Added = {2016-03-14 18:55:31 +0000},
	Date-Modified = {2016-03-14 18:55:31 +0000},
	Journal = {arXiv preprint arXiv:1511.04143},
	Title = {Deep Reinforcement Learning in Parameterized Action Space},
	Year = {2015},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFURvY3MvMTUxMS4wNDE0M3YxLnBkZtIXCxgZV05TLmRhdGFPEQIMAAAAAAIMAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADKQQYMSCsAAAQoOF0QMTUxMS4wNDE0M3YxLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA6gDHtJvzCQAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABERvY3MAEAAIAADKQOnsAAAAEQAIAADSb74UAAAAAQAgBCg4XQQoOFwDsb35AKmYegCQwikABQIVAAUCFAAAvuwAAgB1TWFjaW50b3NoIEhEOlVzZXJzOgBKdXN0ZToARG9jdW1lbnRzOgBDb21wbGV4U3lzdGVtczoAQmlibGlvOgBEb21haW5TcGVjaWZpYzoATWFjaGluZUxlYXJuaW5nOgBEb2NzOgAxNTExLjA0MTQzdjEucGRmAAAOACIAEAAxADUAMQAxAC4AMAA0ADEANAAzAHYAMQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAYFVzZXJzL0p1c3RlL0RvY3VtZW50cy9Db21wbGV4U3lzdGVtcy9CaWJsaW8vRG9tYWluU3BlY2lmaWMvTWFjaGluZUxlYXJuaW5nL0RvY3MvMTUxMS4wNDE0M3YxLnBkZgATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKYAqwCzAsMCxQLKAtUC3gLsAvAC9wMAAwUDEgMVAycDKgMvAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAzE=}}

@inproceedings{vinyals2015show,
	Author = {Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru},
	Booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	Date-Added = {2016-03-14 18:21:08 +0000},
	Date-Modified = {2016-03-14 18:21:08 +0000},
	Pages = {3156--3164},
	Title = {Show and tell: A neural image caption generator},
	Year = {2015},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFERvY3MvMTQxMS40NTU1djEucGRm0hcLGBlXTlMuZGF0YU8RAggAAAAAAggAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAMpBBgxIKwAABCg4XQ8xNDExLjQ1NTV2MS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACEQ020M9vawAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAERG9jcwAQAAgAAMpA6ewAAAARAAgAANDPYVsAAAABACAEKDhdBCg4XAOxvfkAqZh6AJDCKQAFAhUABQIUAAC+7AACAHRNYWNpbnRvc2ggSEQ6VXNlcnM6AEp1c3RlOgBEb2N1bWVudHM6AENvbXBsZXhTeXN0ZW1zOgBCaWJsaW86AERvbWFpblNwZWNpZmljOgBNYWNoaW5lTGVhcm5pbmc6AERvY3M6ADE0MTEuNDU1NXYxLnBkZgAOACAADwAxADQAMQAxAC4ANAA1ADUANQB2ADEALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAF9Vc2Vycy9KdXN0ZS9Eb2N1bWVudHMvQ29tcGxleFN5c3RlbXMvQmlibGlvL0RvbWFpblNwZWNpZmljL01hY2hpbmVMZWFybmluZy9Eb2NzLzE0MTEuNDU1NXYxLnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgClAKoAsgK+AsACxQLQAtkC5wLrAvIC+wMAAw0DEAMiAyUDKgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMs}}
