




@article{kowald2021support,
  title={Support the underground: characteristics of beyond-mainstream music listeners},
  author={Kowald, Dominik and Muellner, Peter and Zangerle, Eva and Bauer, Christine and Schedl, Markus and Lex, Elisabeth},
  journal={EPJ Data Science},
  volume={10},
  number={1},
  pages={1--26},
  year={2021},
  publisher={Springer},
  file={Biblio/DomainSpecific/Music/s13688-021-00268-9.pdf}
}




@article{kim2020pepmusic,
	Author = {Kim, Yongsung and Aiello, Luca Maria and Quercia, Daniele},
	Journal = {EPJ Data Science},
	Number = {1},
	Pages = {13},
	Title = {PepMusic: motivational qualities of songs for daily activities},
	Volume = {9},
	Year = {2020},
	file={Biblio/DomainSpecific/Music/s13688-020-0221-9.pdf}
}




@article{Cowen1924,
	author = {Cowen, Alan S. and Fang, Xia and Sauter, Disa and Keltner, Dacher},
	title = {What music makes us feel: At least 13 dimensions organize subjective experiences associated with music across different cultures},
	volume = {117},
	number = {4},
	pages = {1924--1934},
	year = {2020},
	doi = {10.1073/pnas.1910704117},
	publisher = {National Academy of Sciences},
	abstract = {Do our subjective experiences when listening to music show evidence of universality? And if so, what is the nature of these experiences? With data-driven methodological and statistical approaches, we examined the feelings evoked by 2,168 music excerpts in the United States and China. We uncovered 13 distinct types of experiences that people across 2 different cultures report in listening to music of different kinds. Categories such as {\textquotedblleft}awe{\textquotedblright} drive the experience of music more so than broad affective features like valence. However, emotions that scientists have long treated as discrete can be blended together. Our results provide answers to long-standing questions about the nature of the subjective experiences associated with music.What is the nature of the feelings evoked by music? We investigated how people represent the subjective experiences associated with Western and Chinese music and the form in which these representational processes are preserved across different cultural groups. US (n = 1,591) and Chinese (n = 1,258) participants listened to 2,168 music samples and reported on the specific feelings (e.g., {\textquotedblleft}angry,{\textquotedblright} {\textquotedblleft}dreamy{\textquotedblright}) or broad affective features (e.g., valence, arousal) that they made individuals feel. Using large-scale statistical tools, we uncovered 13 distinct types of subjective experience associated with music in both cultures. Specific feelings such as {\textquotedblleft}triumphant{\textquotedblright} were better preserved across the 2 cultures than levels of valence and arousal, contrasting with theoretical claims that valence and arousal are building blocks of subjective experience. This held true even for music selected on the basis of its valence and arousal levels and for traditional Chinese music. Furthermore, the feelings associated with music were found to occupy continuous gradients, contradicting discrete emotion theories. Our findings, visualized within an interactive map (https://www.ocf.berkeley.edu/\~{}acowen/music.html) reveal a complex, high-dimensional space of subjective experience associated with music in multiple cultures. These findings can inform inquiries ranging from the etiology of affective disorders to the neurological basis of emotion.},
	issn = {0027-8424},
	URL = {https://www.pnas.org/content/117/4/1924},
	eprint = {https://www.pnas.org/content/117/4/1924.full.pdf},
	journal = {Proceedings of the National Academy of Sciences},
	file={Biblio/DomainSpecific/Music/1924.full.pdf}
}



@article{park2020novelty,
  title={Novelty and influence of creative works, and quantifying patterns of advances based on probabilistic references networks},
  author={Park, Doheum and Nam, Juhan and Park, Juyong},
  journal={EPJ Data Science},
  volume={9},
  number={1},
  pages={2},
  year={2020},
  publisher={Springer Berlin Heidelberg},
  file={Biblio/DomainSpecific/Music/s13688-019-0214-8.pdf}
}


@article{mehr2019universality,
  title={Universality and diversity in human song},
  author={Mehr, Samuel A and Singh, Manvir and Knox, Dean and Ketter, Daniel M and Pickens-Jones, Daniel and Atwood, S and Lucas, Christopher and Jacoby, Nori and Egner, Alena A and Hopkins, Erin J and others},
  journal={Science},
  volume={366},
  number={6468},
  year={2019},
  publisher={American Association for the Advancement of Science},
  file={Biblio/DomainSpecific/Music/eaax0868.full.pdf}
}


@article{Gold0428-19,
	author = {Gold, Benjamin P. and Pearce, Marcus T. and Mas-Herrero, Ernest and Dagher, Alain and Zatorre, Robert J.},
	title = {Predictability and uncertainty in the pleasure of music: a reward for learning?},
	elocation-id = {0428-19},
	year = {2019},
	doi = {10.1523/JNEUROSCI.0428-19.2019},
	publisher = {Society for Neuroscience},
	abstract = {Music ranks among the greatest human pleasures. It consistently engages the reward system, and converging evidence implies it exploits predictions to do so. Both prediction confirmations and errors are essential for understanding one{\textquoteright}s environment, and music offers many of each as it manipulates interacting patterns across multiple timescales. Learning models suggest that a balance of these outcomes, i.e., intermediate complexity, optimizes the reduction of uncertainty to rewarding and pleasurable effect. Yet evidence of a similar pattern in music is mixed, hampered by arbitrary measures of complexity. In the present studies, we applied a well-validated information-theoretic model of auditory expectation to systematically measure two key aspects of musical complexity: predictability (operationalized as information content, IC), and uncertainty (entropy). In Study 1, we evaluated how these properties affect musical preferences in 43 male and female participants; in Study 2, we replicated Study 1 in an independent sample of 27 people and assessed the contribution of veridical predictability by presenting the same stimuli seven times. Both studies revealed significant quadratic effects of IC and entropy on liking that outperformed linear effects, indicating reliable preferences for music of intermediate complexity. An interaction between IC and entropy further suggested preferences for more predictability during more uncertain contexts, which would facilitate uncertainty reduction. Repeating stimuli decreased liking ratings but did not disrupt the preference for intermediate complexity. Together, these findings support long-hypothesized optimal zones of predictability and uncertainty in musical pleasure with formal modeling, relating the pleasure of music listening to the intrinsic reward of learning.SIGNIFICANCE STATEMENTAbstract pleasures like music claim much of our time, energy, and money despite lacking any clear adaptive benefits like food or shelter. Yet as music manipulates patterns of melody, rhythm, and more, it proficiently exploits our expectations. Given the importance of anticipating and adapting to our ever-changing environments, making and evaluating uncertain predictions can have strong emotional effects. Accordingly, we present evidence that listeners consistently prefer music of intermediate predictive complexity, and that preferences shift towards expected musical outcomes in more uncertain contexts. These results are consistent with theories that emphasize the intrinsic reward of learning, both by updating inaccurate predictions and validating accurate ones, which is optimal in environments that present manageable predictive challenges, i.e. reducible uncertainty.},
	issn = {0270-6474},
	URL = {https://www.jneurosci.org/content/early/2019/10/11/JNEUROSCI.0428-19.2019},
	eprint = {https://www.jneurosci.org/content/early/2019/10/11/JNEUROSCI.0428-19.2019.full.pdf},file={Biblio/DomainSpecific/Music/
	journal = {Journal of Neuroscience},
	file={Biblio/DomainSpecific/Music/JNEUROSCI.0428-19.2019.full.pdf}
}



@ARTICLE{2016arXiv161004551U,
       author = {{Useche}, Jorge and {Hurtado}, Rafael},
        title = "{Tonal consonance parameters link microscopic and macroscopic properties of music exposing a hidden order in melody}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Sound, Computer Science - Information Theory, Physics - Data Analysis, Statistics and Probability, Physics - Physics and Society, 00A65, 68Q30, H.5.5, J.5},
         year = "2016",
        month = "Oct",
          eid = {arXiv:1610.04551},
        pages = {arXiv:1610.04551},
archivePrefix = {arXiv},
       eprint = {1610.04551},
 primaryClass = {cs.SD},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2016arXiv161004551U},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	file={Biblio/DomainSpecific/Music/1610.04551.pdf}
}




@article{dolgin2019sounds,
title={The sounds of science: biochemistry and the cosmos inspire new music},
author={Dolgin, E.},
journal={Nature},
volume={569},
pages={190-191},
year={2019},
url={https://www.nature.com/articles/d41586-019-01422-0}
}


@article{10.1371/journal.pone.0199892,
     author = {Prieto Curiel, Rafael AND Pappalardo, Luca AND Gabrielli, Lorenzo AND Bishop, Steven Richard},
dhcp-154:DomainSpecific juste$ 
dhcp-154:DomainSpecific juste$ git diff
dhcp-154:DomainSpecific juste$ curl https://www.pnas.org/highwire/citation/851446/bibtext
@article {Goupil3364,
	author = {Goupil, Louise and Aucouturier, Jean-Julien},
	title = {Musical pleasure and musical emotions},
	volume = {116},
	number = {9},
	pages = {3364--3366},
	year = {2019},
	doi = {10.1073/pnas.1900369116},
	publisher = {National Academy of Sciences},
	issn = {0027-8424},
	URL = {https://www.pnas.org/content/116/9/3364},
	eprint = {https://www.pnas.org/content/116/9/3364.full.pdf},
	journal = {Proceedings of the National Academy of Sciences},
	file={Biblio/DomainSpecific/Music/10.1073@pnas.1900369116.pdf}
}



@article{savage2019cultural,
	Author = {Savage, Patrick E. },
	Journal = {Palgrave Communications},
	Number = {1},
	Pages = {16},
	Title = {Cultural evolution of music},
	Volume = {5},
	Year = {2019},
	file={Biblio/DomainSpecific/Music/s41599-019-0221-1.pdf}
}




@article{10.1371/journal.pone.0211860,
    author = {Youngblood, Mason},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Cultural transmission modes of music sampling traditions remain stable despite delocalization in the digital age},
    year = {2019},
    month = {02},
    volume = {14},
    url = {https://doi.org/10.1371/journal.pone.0211860},
    pages = {1-12},
    abstract = {Music sampling is a common practice among hip-hop and electronic producers that has played a critical role in the development of particular subgenres. Artists preferentially sample drum breaks, and previous studies have suggested that these may be culturally transmitted. With the advent of digital sampling technologies and social media the modes of cultural transmission may have shifted, and music communities may have become decoupled from geography. The aim of the current study was to determine whether drum breaks are culturally transmitted through musical collaboration networks, and to identify the factors driving the evolution of these networks. Using network-based diffusion analysis we found strong evidence for the cultural transmission of drum breaks via collaboration between artists, and identified several demographic variables that bias transmission. Additionally, using network evolution methods we found evidence that the structure of the collaboration network is no longer biased by geographic proximity after the year 2000, and that gender disparity has relaxed over the same period. Despite the delocalization of communities by the internet, collaboration remains a key transmission mode of music sampling traditions. The results of this study provide valuable insight into how demographic biases shape cultural transmission in complex networks, and how the evolution of these networks has shifted in the digital age.},
    number = {2},
    doi = {10.1371/journal.pone.0211860},
  file={Biblio/DomainSpecific/Music/journal.pone.0211860.pdf}
}


@article{chang2019body,
  title={Body sway reflects joint emotional expression in music ensemble performance},
  author={Chang, Andrew and Kragness, Haley E and Livingstone, Steven R and Bosnyak, Dan J and Trainor, Laurel J},
  journal={Scientific reports},
  volume={9},
  number={1},
  pages={205},
  year={2019},
  publisher={Nature Publishing Group},
  file={Biblio/DomainSpecific/Music/s41598-018-36358-4.pdf}
}



@article{Lenc8221,
	author = {Lenc, Tomas and Keller, Peter E. and Varlet, Manuel and Nozaradan, Sylvie},
	title = {Neural tracking of the musical beat is enhanced by low-frequency sounds},
	volume = {115},
	number = {32},
	pages = {8221--8226},
	year = {2018},
	doi = {10.1073/pnas.1801421115},
	publisher = {National Academy of Sciences},
	abstract = {Bass sounds play a special role in conveying the rhythm and stimulating motor entrainment to the beat of music. However, the biological roots of this culturally widespread musical practice remain mysterious, despite its fundamental relevance in the sciences and arts, and also for music-assisted clinical rehabilitation of motor disorders. Here, we show that this musical convention may exploit a neurophysiological mechanism whereby low-frequency sounds shape neural representations of rhythmic input at the cortical level by boosting selective neural locking to the beat, thus explaining the privileged role of bass sounds in driving people to move along with the musical beat.Music makes us move, and using bass instruments to build the rhythmic foundations of music is especially effective at inducing people to dance to periodic pulse-like beats. Here, we show that this culturally widespread practice may exploit a neurophysiological mechanism whereby low-frequency sounds shape the neural representations of rhythmic input by boosting selective locking to the beat. Cortical activity was captured using electroencephalography (EEG) while participants listened to a regular rhythm or to a relatively complex syncopated rhythm conveyed either by low tones (130 Hz) or high tones (1236.8 Hz). We found that cortical activity at the frequency of the perceived beat is selectively enhanced compared with other frequencies in the EEG spectrum when rhythms are conveyed by bass sounds. This effect is unlikely to arise from early cochlear processes, as revealed by auditory physiological modeling, and was particularly pronounced for the complex rhythm requiring endogenous generation of the beat. The effect is likewise not attributable to differences in perceived loudness between low and high tones, as a control experiment manipulating sound intensity alone did not yield similar results. Finally, the privileged role of bass sounds is contingent on allocation of attentional resources to the temporal properties of the stimulus, as revealed by a further control experiment examining the role of a behavioral task. Together, our results provide a neurobiological basis for the convention of using bass instruments to carry the rhythmic foundations of music and to drive people to move to the beat.},
	issn = {0027-8424},
	URL = {http://www.pnas.org/content/115/32/8221},
	eprint = {http://www.pnas.org/content/115/32/8221.full.pdf},
	journal = {Proceedings of the National Academy of Sciences},
 	file={Biblio/DomainSpecific/Music/8221.full.pdf}
}


@article{cheng2017music,
  title={Music induced happy mood suppresses the neural responses to other’s pain: Evidences from an ERP study},
  author={Cheng, Jiaping and Jiao, Can and Luo, Yuejia and Cui, Fang},
  journal={Scientific reports},
  volume={7},
  number={1},
  pages={13054},
  year={2017},
  publisher={Nature Publishing Group},
  file={Biblio/DomainSpecific/Music/s41598-017-13386-0.pdf}
}



@article{bowling2017vocal,
  title={Vocal similarity predicts the relative attraction of musical chords},
  author={Bowling, Daniel L and Purves, Dale and Gill, Kamraan Z},
  journal={Proceedings of the National Academy of Sciences},
  pages={201713206},
  year={2017},
  publisher={National Acad Sciences},
  file={Biblio/DomainSpecific/Music/PNAS-2018-Bowling-216-21.pdf}
}




@ARTICLE{2017arXiv171208336N,
   author = {{Nag}, S. and {Sanyal}, S. and {Banerjee}, A. and {Sengupta}, R. and 
	{Ghosh}, D.},
    title = "{Music of Brain and Music on Brain: A Novel EEG Sonification approach}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1712.08336},
 primaryClass = "q-bio.NC",
 keywords = {Quantitative Biology - Neurons and Cognition, Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing, Physics - Data Analysis, Statistics and Probability},
     year = 2017,
    month = dec,
   adsurl = {http://adsabs.harvard.edu/abs/2017arXiv171208336N},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System},
  file={Biblio/DomainSpecific/Music/1712.08336.pdf}
}




@ARTICLE{2017arXiv171207417B,
   author = {{beim Graben}, P. and {Blutner}, R.},
    title = "{Quantum approaches to music cognition}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1712.07417},
 primaryClass = "q-bio.NC",
 keywords = {Quantitative Biology - Neurons and Cognition},
     year = 2017,
    month = dec,
   adsurl = {http://adsabs.harvard.edu/abs/2017arXiv171207417B},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System},
  file={Biblio/DomainSpecific/Music/1712.07417.pdf}
}



@ARTICLE{2017arXiv171202898S,
   author = {{Shuvaev}, S. and {Giaffar}, H. and {Koulakov}, A.~A.},
    title = "{Representations of Sound in Deep Learning of Audio Features from Music}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1712.02898},
 primaryClass = "cs.SD",
 keywords = {Computer Science - Sound, Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Audio and Speech Processing, Quantitative Biology - Neurons and Cognition},
     year = 2017,
    month = dec,
   adsurl = {http://adsabs.harvard.edu/abs/2017arXiv171202898S},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System},
  file={Biblio/DomainSpecific/Music/1712.02898.pdf}
}




@ARTICLE{2018arXiv180506506K,
   author = {{Khosravani}, A. and {Rasinariu}, C.},
    title = "{Emergence of Benford's Law in Classical Music}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1805.06506},
 primaryClass = "physics.soc-ph",
 keywords = {Physics - Physics and Society, Mathematics - Probability},
     year = 2018,
    month = may,
   adsurl = {http://adsabs.harvard.edu/abs/2018arXiv180506506K},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System},
  file={Biblio/DomainSpecific/Music/1805.06506.pdf}
}



