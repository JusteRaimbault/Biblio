







@Article{Preiss2019,
author="Preiss, Judita",
title="Is automatic detection of hidden knowledge an anomaly?",
journal="BMC Bioinformatics",
year="2019",
month="May",
day="29",
volume="20",
number="10",
pages="251",
abstract="The quantity of documents being published requires researchers to specialize to a narrower field, meaning that inferable connections between publications (particularly from different domains) can be missed. This has given rise to automatic literature based discovery (LBD). However, unless heavily filtered, LBD generates more potential new knowledge than can be manually verified and another form of selection is required before the results can be passed onto a user. Since a large proportion of the automatically generated hidden knowledge is valid but generally known, we investigate the hypothesis that non trivial, interesting, hidden knowledge can be treated as an anomaly and identified using anomaly detection approaches.",
issn="1471-2105",
doi="10.1186/s12859-019-2815-4",
url="https://doi.org/10.1186/s12859-019-2815-4",
file={Docs/s12859-019-2815-4.pdf}
}



@inproceedings{dartnell2005assisting,
  title={Assisting scientific discovery with an adaptive problem solver},
  author={Dartnell, Christopher and Sallantin, Jean},
  booktitle={International Conference on Discovery Science},
  pages={99--112},
  year={2005},
  organization={Springer},
  file={Docs/dartnell2005.pdf}
}



@article{Rzhetsky14569,
	author = {Rzhetsky, Andrey and Foster, Jacob G. and Foster, Ian T. and Evans, James A.},
	title = {Choosing experiments to accelerate collective discovery},
	volume = {112},
	number = {47},
	pages = {14569--14574},
	year = {2015},
	doi = {10.1073/pnas.1509757112},
	publisher = {National Academy of Sciences},
	abstract = {Scientists perform a tiny subset of all possible experiments. What characterizes the experiments they choose? And what are the consequences of those choices for the pace of scientific discovery? We model scientific knowledge as a network and science as a sequence of experiments designed to gradually uncover it. By analyzing millions of biomedical articles published over 30 y, we find that biomedical scientists pursue conservative research strategies exploring the local neighborhood of central, important molecules. Although such strategies probably serve scientific careers, we show that they slow scientific advance, especially in mature fields, where more risk and less redundant experimentation would accelerate discovery of the network. We also consider institutional arrangements that could help science pursue these more efficient strategies.A scientist{\textquoteright}s choice of research problem affects his or her personal career trajectory. Scientists{\textquoteright} combined choices affect the direction and efficiency of scientific discovery as a whole. In this paper, we infer preferences that shape problem selection from patterns of published findings and then quantify their efficiency. We represent research problems as links between scientific entities in a knowledge network. We then build a generative model of discovery informed by qualitative research on scientific problem selection. We map salient features from this literature to key network properties: an entity{\textquoteright}s importance corresponds to its degree centrality, and a problem{\textquoteright}s difficulty corresponds to the network distance it spans. Drawing on millions of papers and patents published over 30 years, we use this model to infer the typical research strategy used to explore chemical relationships in biomedicine. This strategy generates conservative research choices focused on building up knowledge around important molecules. These choices become more conservative over time. The observed strategy is efficient for initial exploration of the network and supports scientific careers that require steady output, but is inefficient for science as a whole. Through supercomputer experiments on a sample of the network, we study thousands of alternatives and identify strategies much more efficient at exploring mature knowledge networks. We find that increased risk-taking and the publication of experimental failures would substantially improve the speed of discovery. We consider institutional shifts in grant making, evaluation, and publication that would help realize these efficiencies.},
	issn = {0027-8424},
	URL = {https://www.pnas.org/content/112/47/14569},
	eprint = {https://www.pnas.org/content/112/47/14569.full.pdf},
	journal = {Proceedings of the National Academy of Sciences},
	file={Docs/14569.full.pdf}
}




@article{Akerlof13228,
	author = {Akerlof, George A. and Michaillat, Pascal},
	title = {Persistence of false paradigms in low-power sciences},
	volume = {115},
	number = {52},
	pages = {13228--13233},
	year = {2018},
	doi = {10.1073/pnas.1816454115},
	publisher = {National Academy of Sciences},
	abstract = {It is believed that a lack of experimental evidence (typical in the social sciences) slows but does not prevent the adoption of true theories. We evaluate this belief using a model of scientific research and promotion in which tenured scientists are slightly biased toward tenure candidates with similar beliefs. We find that when a science lacks evidence to discriminate between theories, or when tenure decisions do not rely on available evidence, true theories may not be adopted. The nonadoption of heliocentric theory in the 16th century, the persistence of bloodletting in the 19th century, the nonadoption of underconsumption theory in the early 20th century, and the persistence of radical mastectomy in the 20th century illustrate such risk.We develop a model describing how false paradigms may persist, hindering scientific progress. The model features two paradigms, one describing reality better than the other. Tenured scientists display homophily: They favor tenure candidates who adhere to their paradigm. As in statistics, power is the probability (absent any bias) of denying tenure to scientists adhering to the false paradigm. The model shows that because of homophily, when power is low, the false paradigm may prevail. Then, only an increase in power can ignite convergence to the true paradigm. Historical case studies suggest that low power comes either from lack of empirical evidence or from reluctance to base tenure decisions on available evidence.},
	issn = {0027-8424},
	URL = {https://www.pnas.org/content/115/52/13228},
	eprint = {https://www.pnas.org/content/115/52/13228.full.pdf},
	journal = {Proceedings of the National Academy of Sciences},
	file={Docs/13228.full.pdf}
}



@Article{Morgan2018,
author="Morgan, Allison C.
and Economou, Dimitrios J.
and Way, Samuel F.
and Clauset, Aaron",
title="Prestige drives epistemic inequality in the diffusion of scientific ideas",
journal="EPJ Data Science",
year="2018",
month="Oct",
day="19",
volume="7",
number="1",
pages="40",
abstract="The spread of ideas in the scientific community is often viewed as a competition, in which good ideas spread further because of greater intrinsic fitness, and publication venue and citation counts correlate with importance and impact. However, relatively little is known about how structural factors influence the spread of ideas, and specifically how where an idea originates might influence how it spreads. Here, we investigate the role of faculty hiring networks, which embody the set of researcher transitions from doctoral to faculty institutions, in shaping the spread of ideas in computer science, and the importance of where in the network an idea originates. We consider comprehensive data on the hiring events of 5032 faculty at all 205 Ph.D.-granting departments of computer science in the U.S. and Canada, and on the timing and titles of 200,476 associated publications. Analyzing five popular research topics, we show empirically that faculty hiring can and does facilitate the spread of ideas in science. Having established such a mechanism, we then analyze its potential consequences using epidemic models to simulate the generic spread of research ideas and quantify the impact of where an idea originates on its longterm diffusion across the network. We find that research from prestigious institutions spreads more quickly and completely than work of similar quality originating from less prestigious institutions. Our analyses establish the theoretical trade-offs between university prestige and the quality of ideas necessary for efficient circulation. Our results establish faculty hiring as an underlying mechanism that drives the persistent epistemic advantage observed for elite institutions, and provide a theoretical lower bound for the impact of structural inequality in shaping the spread of ideas in science.",
issn="2193-1127",
doi="10.1140/epjds/s13688-018-0166-4",
url="https://doi.org/10.1140/epjds/s13688-018-0166-4",
file={Docs/s13688-018-0166-4.pdf}
}






@article{doi:10.1177/2515245917747646,
author = {R. Silberzahn and E. L. Uhlmann and D. P. Martin and P. Anselmi and F. Aust and E. Awtrey and Š. Bahník and F. Bai and C. Bannard and E. Bonnier and R. Carlsson and F. Cheung and G. Christensen and R. Clay and M. A. Craig and A. Dalla Rosa and L. Dam and M. H. Evans and I. Flores Cervantes and N. Fong and M. Gamez-Djokic and A. Glenz and S. Gordon-McKeon and T. J. Heaton and K. Hederos and M. Heene and A. J. Hofelich Mohr and F. Högden and K. Hui and M. Johannesson and J. Kalodimos and E. Kaszubowski and D. M. Kennedy and R. Lei and T. A. Lindsay and S. Liverani and C. R. Madan and D. Molden and E. Molleman and R. D. Morey and L. B. Mulder and B. R. Nijstad and N. G. Pope and B. Pope and J. M. Prenoveau and F. Rink and E. Robusto and H. Roderique and A. Sandberg and E. Schlüter and F. D. Schönbrodt and M. F. Sherman and S. A. Sommer and K. Sotak and S. Spain and C. Spörlein and T. Stafford and L. Stefanutti and S. Tauber and J. Ullrich and M. Vianello and E.-J. Wagenmakers and M. Witkowiak and S. Yoon and B. A. Nosek},
title ={Many Analysts, One Data Set: Making Transparent How Variations in Analytic Choices Affect Results},
journal = {Advances in Methods and Practices in Psychological Science},
volume = {0},
number = {0},
pages = {2515245917747646},
year = {0},
doi = {10.1177/2515245917747646},

URL = { 
        https://doi.org/10.1177/2515245917747646
    
},
eprint = { 
        https://doi.org/10.1177/2515245917747646
    
}
,
    abstract = { Twenty-nine teams involving 61 analysts used the same data set to address the same research question: whether soccer referees are more likely to give red cards to dark-skin-toned players than to light-skin-toned players. Analytic approaches varied widely across the teams, and the estimated effect sizes ranged from 0.89 to 2.93 (Mdn = 1.31) in odds-ratio units. Twenty teams (69\%) found a statistically significant positive effect, and 9 teams (31\%) did not observe a significant relationship. Overall, the 29 different analyses used 21 unique combinations of covariates. Neither analysts’ prior beliefs about the effect of interest nor their level of expertise readily explained the variation in the outcomes of the analyses. Peer ratings of the quality of the analyses also did not account for the variability. These findings suggest that significant variation in the results of analyses of complex data may be difficult to avoid, even by experts with honest intentions. Crowdsourcing data analysis, a strategy in which numerous research teams are recruited to simultaneously investigate the same research question, makes transparent how defensible, yet subjective, analytic choices influence research results. },
file={Docs/10.1177@2515245917747646.pdf}
}





@article{doi:10.1093/biosci/biy083,
author = {Fitzpatrick, Courtney L and Hobson, Elizabeth A and Mendelson, Tamra C and Rodríguez, Rafael L and Safran, Rebecca J and Scordato, Elizabeth S C and Servedio, Maria R and Stern, Caitlin A and Symes, Laurel B and Kopp, Michael},
title = {Theory Meets Empiry: A Citation Network Analysis},
journal = {BioScience},
volume = {},
number = {},
pages = {biy083},
year = {2018},
doi = {10.1093/biosci/biy083},
URL = {http://dx.doi.org/10.1093/biosci/biy083},
eprint = {/oup/backfile/content_public/journal/bioscience/pap/10.1093_biosci_biy083/2/biy083.pdf},
file={Docs/biy083.pdf}
}


