


@article{roesch2020new,
title={New journal for reproduction and replication results},
author={Roesch, E.B. and Rougier, N.},
journal={Nature},
volume={581},
pages={30},
year={2020},
doi={10.1038/d41586-020-01328-2},
url={https://www.nature.com/articles/d41586-020-01328-2},
file={Biblio/DomainSpecific/Reproducibility/d41586-020-01328-2.pdf}
}


@article{10.1371/journal.pbio.3000691,
    author = {Nosek, Brian A. AND Errington, Timothy M.},
    journal = {PLOS Biology},
    publisher = {Public Library of Science},
    title = {What is replication?},
    year = {2020},
    month = {03},
    volume = {18},
    url = {https://doi.org/10.1371/journal.pbio.3000691},
    pages = {1-8},
    abstract = {What is replication? This Perspective article proposes that the answer shifts the conception of replication from a boring, uncreative, housekeeping activity to an exciting, generative, vital contributor to research progress.},
    number = {3},
    doi = {10.1371/journal.pbio.3000691},
    file={Biblio/DomainSpecific/Reproducibility/journal.pbio.3000691.pdf}
}



@article{Wilson5559,
	author = {Wilson, Brent M. and Harris, Christine R. and Wixted, John T.},
	title = {Science is not a signal detection problem},
	volume = {117},
	number = {11},
	pages = {5559--5567},
	year = {2020},
	doi = {10.1073/pnas.1914237117},
	publisher = {National Academy of Sciences},
	abstract = {The perceived replication crisis and the reforms designed to address it are grounded in the notion that science is a binary signal detection problem. However, contrary to null hypothesis significance testing (NHST) logic, the magnitude of the underlying effect size for a given experiment is best conceptualized as a random draw from a continuous distribution, not as a random draw from a dichotomous distribution (null vs. alternative). Moreover, because continuously distributed effects selected using a P \&lt; 0.05 filter must be inflated, the fact that they are smaller when replicated (reflecting regression to the mean) is no reason to sound the alarm. Considered from this perspective, recent replication efforts suggest that most published P \&lt; 0.05 scientific findings are {\textquotedblleft}true{\textquotedblright} (i.e., in the correct direction), with observed effect sizes that are inflated to varying degrees. We propose that original science is a screening process, one that adopts NHST logic as a useful fiction for selecting true effects that are potentially large enough to be of interest to other scientists. Unlike original science, replication science seeks to precisely measure the underlying effect size associated with an experimental protocol via large-N direct replication, without regard for statistical significance. Registered reports are well suited to (often resource-intensive) direct replications, which should focus on influential findings and be published regardless of outcome. Conceptual replications play an important but separate role in validating theories. However, because they are part of NHST-based original science, conceptual replications cannot serve as the field{\textquoteright}s self-correction mechanism. Only direct replications can do that.},
	issn = {0027-8424},
	URL = {https://www.pnas.org/content/117/11/5559},
	eprint = {https://www.pnas.org/content/117/11/5559.full.pdf},
	journal = {Proceedings of the National Academy of Sciences},
	file={Biblio/DomainSpecific/Reproducibility/10.1073@pnas.1914237117.pdf}
}



@book{kitzes2017practice,
  title={The practice of reproducible research: case studies and lessons from the data-intensive sciences},
  author={Kitzes, Justin and Turek, Daniel and Deniz, Fatma},
  year={2017},
  publisher={Univ of California Press},
  file={Biblio/DomainSpecific/Reproducibility/the-practice-of-reproducible-research.pdf}
}


@article{nature2020irreproducibility,
title={Irreproducibility is not a sign of failure, but an inspiration for fresh ideas},
author={Nature Editorial}
journal={Nature},
volume={578},
pages={191-192},
year={2020},
file={Biblio/DomainSpecific/Reproducibility/d41586-020-00380-2.pdf},
url={https://www.nature.com/articles/d41586-020-00380-2},
doi={10.1038/d41586-020-00380-2}
}


@article{chawla2020software,
title={Software searches out reproducibility issues in scientific papers},
author={Chawla, D.S.},
journal={Nature},
year={2020},
doi={10.1038/d41586-020-00104-6},
url={https://www.nature.com/articles/d41586-020-00104-6}
}

@article{Bryan25535,
	author = {Bryan, Christopher J. and Yeager, David S. and O{\textquoteright}Brien, Joseph M.},
	title = {Replicator degrees of freedom allow publication of misleading failures to replicate},
	volume = {116},
	number = {51},
	pages = {25535--25545},
	year = {2019},
	doi = {10.1073/pnas.1910951116},
	publisher = {National Academy of Sciences},
	abstract = {We show that commonly exercised flexibility at the experimental design and data analysis stages of replication testing makes it easy to publish false-negative replication results while maintaining the impression of methodological rigor. These findings have important implications for how the many ostensible nonreplications already in the literature should be interpreted and for how future replication tests should be conducted.In recent years, the field of psychology has begun to conduct replication tests on a large scale. Here, we show that {\textquotedblleft}replicator degrees of freedom{\textquotedblright} make it far too easy to obtain and publish false-negative replication results, even while appearing to adhere to strict methodological standards. Specifically, using data from an ongoing debate, we show that commonly exercised flexibility at the experimental design and data analysis stages of replication testing can make it appear that a finding was not replicated when, in fact, it was. The debate that we focus on is representative, on key dimensions, of a large number of other replication tests in psychology that have been published in recent years, suggesting that the lessons of this analysis may be far reaching. The problems with current practice in replication science that we uncover here are particularly worrisome because they are not adequately addressed by the field{\textquoteright}s standard remedies, including preregistration. Implications for how the field could develop more effective methodological standards for replication are discussed.},
	issn = {0027-8424},
	URL = {https://www.pnas.org/content/116/51/25535},
	eprint = {https://www.pnas.org/content/116/51/25535.full.pdf},
	journal = {Proceedings of the National Academy of Sciences},
	file={Biblio/DomainSpecific/Reproducibility/25535.full.pdf}
}


@article{hinsen2019challenge,
author={Hinsen, K. and Rougier, N.},
title={Challenge to test reproducibility of old computer code},
journal={Nature},
volume={574},
pages={634}
year={2019},
doi={10.1038/d41586-019-03296-8},file={Biblio/DomainSpecific/Reproducibility/
file={Biblio/DomainSpecific/Reproducibility/d41586-019-03296-8.pdf},
url={https://www.nature.com/articles/d41586-019-03296-8}
}


@article{patil2016statistical,
  title={A statistical definition for reproducibility and replicability},
  author={Patil, Prasad and Peng, Roger D and Leek, Jeffrey},
  journal={BioRxiv},
  pages={066803},
  year={2016},
  publisher={Cold Spring Harbor Laboratory},
  file={Biblio/DomainSpecific/Reproducibility/066803.full.pdf}
}




@inproceedings{dragicevic:hal-01976951,
  TITLE = {{Increasing the Transparency of Research Papers with Explorable Multiverse Analyses}},
  AUTHOR = {Dragicevic, Pierre and Jansen, Yvonne and Sarma, Abhraneel and Kay, Matthew and Chevalier, Fanny},
  URL = {https://hal.inria.fr/hal-01976951},
  BOOKTITLE = {{CHI 2019 - The ACM CHI Conference on Human Factors in Computing Systems}},
  ADDRESS = {Glasgow, United Kingdom},
  YEAR = {2019},
  MONTH = May,
  DOI = {10.1145/3290605.3300295},
  KEYWORDS = {multiverse analysis ; explorable explanation ; statistics ; transparent reporting ; interactive documents},
  PDF = {https://hal.inria.fr/hal-01976951/file/Interactive_Paper_CHI2019_camera_ready.pdf},
  HAL_ID = {hal-01976951},
  HAL_VERSION = {v1},
  file={Biblio/DomainSpecific/Reproducibility/Interactive_Paper_CHI2019_camera_ready.pdf}
}



@article{perkel2019pioneering,
  title={Pioneering ‘live-code’ article allows scientists to play with each other’s results},
  author={Perkel, J.M.},
  journal={Nature},
  year={2019},
  volume={567},
  pages={17--18},
  file={Biblio/DomainSpecific/Reproducibility/d41586-019-00724-7.pdf},
  url={https://www.nature.com/articles/d41586-019-00724-7}
}


@article{govoni2019qresp,
  title={Qresp, a tool for curating, discovering and exploring reproducible scientific papers},
  author={Govoni, Marco and Munakami, Milson and Tanikanti, Aditya and Skone, Jonathan H and Runesha, Hakizumwami B and Giberti, Federico and de Pablo, Juan and Galli, Giulia},
  journal={Scientific Data},
  volume={6},
  pages={190002},
  year={2019},
  publisher={Nature Publishing Group},
  file={Biblio/DomainSpecific/Reproducibility/sdata20192.pdf}
}


@article{juergens2018evaluation,
	Author = {Juergens, Hannes and Niemeijer, Matthijs and Jennings-Antipov, Laura D. and Mans, Robert and Morel, Jack and van Maris, Antonius J. A. and Pronk, Jack T. and Gardner, Timothy S.},
	Journal = {Scientific Data},
	Month = {10},
	Pages = {180195 EP  -},
	Title = {Evaluation of a novel cloud-based software platform for structured experiment design and linked data analytics},
	Volume = {5},
	Year = {2018}
	file={Biblio/DomainSpecific/Reproducibility/sdata2018195.pdf}
}





@article{perkel2018toolkit,
  author={J. M. Perkel},
  title={A toolkit for data transparency takes shape},
  journal={Nature},
  pages={513--515},
  volume={560},
  doi={10.1038/d41586-018-05990-5},
  year={2018},
  file={Biblio/DomainSpecific/Reproducibility/d41586-018-05990-5.pdf}
}



@ARTICLE{2018arXiv180500400B,
   author = {{Brinckman}, A. and {Chard}, K. and {Gaffney}, N. and {Hategan}, M. and 
	{Jones}, M.~B. and {Kowalik}, K. and {Kulasekaran}, S. and {Lud{\"a}scher}, B. and 
	{Mecum}, B.~D. and {Nabrzyski}, J. and {Stodden}, V. and {Taylor}, I.~J. and 
	{Turk}, M.~J. and {Turner}, K.},
    title = "{Computing Environments for Reproducibility: Capturing the ``Whole Tale''}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1805.00400},
 primaryClass = "cs.CY",
 keywords = {Computer Science - Computers and Society},
     year = 2018,
    month = may,
   adsurl = {http://adsabs.harvard.edu/abs/2018arXiv180500400B},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System},
  file={Biblio/DomainSpecific/Reproducibility/1805.00400.pdf}
}





@article{shiffrin2018scientific,
	  title={Scientific progress despite irreproducibility: A seeming paradox},
	    author={Shiffrin, Richard M and B{\"o}rner, Katy and Stigler, Stephen M},
	      journal={Proceedings of the National Academy of Sciences},
	        volume={115},
		  number={11},
		    pages={2632--2639},
		      year={2018},
		        publisher={National Acad Sciences},
			file={Biblio/DomainSpecific/Reproducibility/2632.full.pdf}
}




@article{fanelli2018opinion,
	  title={Opinion: Is science really facing a reproducibility crisis, and do we need it to?},
	    author={Fanelli, Daniele},
	      journal={Proceedings of the National Academy of Sciences},
	        volume={115},
		  number={11},
		    pages={2628--2631},
		      year={2018},
		        publisher={National Acad Sciences},
			file={Biblio/DomainSpecific/Reproducibility/2628.full.pdf}
}



@article{boutron2018misrepresentation,
	  title={Misrepresentation and distortion of research in biomedical literature},
	    author={Boutron, Isabelle and Ravaud, Philippe},
	      journal={Proceedings of the National Academy of Sciences},
	        volume={115},
		  number={11},
		    pages={2613--2619},
		      year={2018},
		        publisher={National Acad Sciences},
			file={Biblio/DomainSpecific/Reproducibility/2613.full.pdf}
}




@article{stodden2018empirical,
	  title={An empirical analysis of journal policy effectiveness for computational reproducibility},
	    author={Stodden, Victoria and Seiler, Jennifer and Ma, Zhaokun},
	      journal={Proceedings of the National Academy of Sciences},
	        volume={115},
		  number={11},
		    pages={2584--2589},
		      year={2018},
		        publisher={National Acad Sciences},
			file={Biblio/DomainSpecific/Reproducibility/2584.full.pdf}
}



